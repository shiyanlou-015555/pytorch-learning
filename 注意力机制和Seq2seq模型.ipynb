{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_he9lhbo",
    "id": "DC31ED3C042A4C68936B8C9C9493C4D4",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# [åŸç†](https://blog.csdn.net/hpulfc/article/details/80448570)\n",
    "![](https://img-blog.csdn.net/20180627114128329?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hwdWxmYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n",
    "å…¶ä¸­fæ˜¯Decoderçš„éçº¿æ€§å˜æ¢å‡½æ•°ã€‚ä»è¿™é‡Œå¯ä»¥çœ‹å‡ºï¼Œåœ¨ç”Ÿæˆç›®æ ‡å¥å­çš„å•è¯æ—¶ï¼Œä¸è®ºç”Ÿæˆå“ªä¸ªå•è¯ï¼Œå®ƒä»¬ä½¿ç”¨çš„è¾“å…¥å¥å­Sourceçš„è¯­ä¹‰ç¼–ç Céƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚\n",
    "\n",
    "    è€Œè¯­ä¹‰ç¼–ç Cæ˜¯ç”±å¥å­Sourceçš„æ¯ä¸ªå•è¯ç»è¿‡Encoder ç¼–ç äº§ç”Ÿçš„ï¼Œè¿™æ„å‘³ç€ä¸è®ºæ˜¯ç”Ÿæˆå“ªä¸ªå•è¯ï¼Œy1,y2è¿˜æ˜¯y3ï¼Œå…¶å®å¥å­Sourceä¸­ä»»æ„å•è¯å¯¹ç”ŸæˆæŸä¸ªç›®æ ‡å•è¯yiæ¥è¯´å½±å“åŠ›éƒ½æ˜¯ç›¸åŒçš„ï¼Œè¿™æ˜¯ä¸ºä½•è¯´è¿™ä¸ªæ¨¡å‹æ²¡æœ‰ä½“ç°å‡ºæ³¨æ„åŠ›çš„ç¼˜ç”±ã€‚è¿™ç±»ä¼¼äºäººç±»çœ‹åˆ°çœ¼å‰çš„ç”»é¢ï¼Œä½†æ˜¯çœ¼ä¸­å´æ²¡æœ‰æ³¨æ„ç„¦ç‚¹ä¸€æ ·ã€‚\n",
    "\n",
    "    å¦‚æœæ‹¿æœºå™¨ç¿»è¯‘æ¥è§£é‡Šè¿™ä¸ªåˆ†å¿ƒæ¨¡å‹çš„Encoder-Decoderæ¡†æ¶æ›´å¥½ç†è§£ï¼Œæ¯”å¦‚è¾“å…¥çš„æ˜¯è‹±æ–‡å¥å­ï¼šTom chase Jerryï¼ŒEncoder-Decoderæ¡†æ¶é€æ­¥ç”Ÿæˆä¸­æ–‡å•è¯ï¼šâ€œæ±¤å§†â€ï¼Œâ€œè¿½é€â€ï¼Œâ€œæ°ç‘â€ã€‚\n",
    "\n",
    "    åœ¨ç¿»è¯‘â€œæ°ç‘â€è¿™ä¸ªä¸­æ–‡å•è¯çš„æ—¶å€™ï¼Œåˆ†å¿ƒæ¨¡å‹é‡Œé¢çš„æ¯ä¸ªè‹±æ–‡å•è¯å¯¹äºç¿»è¯‘ç›®æ ‡å•è¯â€œæ°ç‘â€è´¡çŒ®æ˜¯ç›¸åŒçš„ï¼Œå¾ˆæ˜æ˜¾è¿™é‡Œä¸å¤ªåˆç†ï¼Œæ˜¾ç„¶â€œJerryâ€å¯¹äºç¿»è¯‘æˆâ€œæ°ç‘â€æ›´é‡è¦ï¼Œä½†æ˜¯åˆ†å¿ƒæ¨¡å‹æ˜¯æ— æ³•ä½“ç°è¿™ä¸€ç‚¹çš„ï¼Œè¿™å°±æ˜¯ä¸ºä½•è¯´å®ƒæ²¡æœ‰å¼•å…¥æ³¨æ„åŠ›çš„åŸå› ã€‚\n",
    "\n",
    "    æ²¡æœ‰å¼•å…¥æ³¨æ„åŠ›çš„æ¨¡å‹åœ¨è¾“å…¥å¥å­æ¯”è¾ƒçŸ­çš„æ—¶å€™é—®é¢˜ä¸å¤§ï¼Œä½†æ˜¯å¦‚æœè¾“å…¥å¥å­æ¯”è¾ƒé•¿ï¼Œæ­¤æ—¶æ‰€æœ‰è¯­ä¹‰å®Œå…¨é€šè¿‡ä¸€ä¸ªä¸­é—´è¯­ä¹‰å‘é‡æ¥è¡¨ç¤ºï¼Œå•è¯è‡ªèº«çš„ä¿¡æ¯å·²ç»æ¶ˆå¤±ï¼Œå¯æƒ³è€ŒçŸ¥ä¼šä¸¢å¤±å¾ˆå¤šç»†èŠ‚ä¿¡æ¯ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä½•è¦å¼•å…¥æ³¨æ„åŠ›æ¨¡å‹çš„é‡è¦åŸå› ã€‚\n",
    "\n",
    "    ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå¦‚æœå¼•å…¥Attentionæ¨¡å‹çš„è¯ï¼Œåº”è¯¥åœ¨ç¿»è¯‘â€œæ°ç‘â€çš„æ—¶å€™ï¼Œä½“ç°å‡ºè‹±æ–‡å•è¯å¯¹äºç¿»è¯‘å½“å‰ä¸­æ–‡å•è¯ä¸åŒçš„å½±å“ç¨‹åº¦ï¼Œæ¯”å¦‚ç»™å‡ºç±»ä¼¼ä¸‹é¢ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒå€¼ï¼š\n",
    "\n",
    "    ï¼ˆTom,0.3ï¼‰(Chase,0.2) (Jerry,0.5)\n",
    "\n",
    "    æ¯ä¸ªè‹±æ–‡å•è¯çš„æ¦‚ç‡ä»£è¡¨äº†ç¿»è¯‘å½“å‰å•è¯â€œæ°ç‘â€æ—¶ï¼Œæ³¨æ„åŠ›åˆ†é…æ¨¡å‹åˆ†é…ç»™ä¸åŒè‹±æ–‡å•è¯çš„æ³¨æ„åŠ›å¤§å°ã€‚è¿™å¯¹äºæ­£ç¡®ç¿»è¯‘ç›®æ ‡è¯­å•è¯è‚¯å®šæ˜¯æœ‰å¸®åŠ©çš„ï¼Œå› ä¸ºå¼•å…¥äº†æ–°çš„ä¿¡æ¯ã€‚\n",
    "\n",
    "    åŒç†ï¼Œç›®æ ‡å¥å­ä¸­çš„æ¯ä¸ªå•è¯éƒ½åº”è¯¥å­¦ä¼šå…¶å¯¹åº”çš„æºè¯­å¥å­ä¸­å•è¯çš„æ³¨æ„åŠ›åˆ†é…æ¦‚ç‡ä¿¡æ¯ã€‚è¿™æ„å‘³ç€åœ¨ç”Ÿæˆæ¯ä¸ªå•è¯yiçš„æ—¶å€™ï¼ŒåŸå…ˆéƒ½æ˜¯ç›¸åŒçš„ä¸­é—´è¯­ä¹‰è¡¨ç¤ºCä¼šè¢«æ›¿æ¢æˆæ ¹æ®å½“å‰ç”Ÿæˆå•è¯è€Œä¸æ–­å˜åŒ–çš„Ciã€‚ç†è§£Attentionæ¨¡å‹çš„å…³é”®å°±æ˜¯è¿™é‡Œï¼Œå³ç”±å›ºå®šçš„ä¸­é—´è¯­ä¹‰è¡¨ç¤ºCæ¢æˆäº†æ ¹æ®å½“å‰è¾“å‡ºå•è¯æ¥è°ƒæ•´æˆåŠ å…¥æ³¨æ„åŠ›æ¨¡å‹çš„å˜åŒ–çš„Ciã€‚å¢åŠ äº†æ³¨æ„åŠ›æ¨¡å‹çš„Encoder-Decoderæ¡†æ¶ç†è§£èµ·æ¥å¦‚å›¾3æ‰€ç¤ºã€‚\n",
    "\n",
    "\n",
    "# æ³¨æ„åŠ›æœºåˆ¶\n",
    "åœ¨â€œç¼–ç å™¨â€”è§£ç å™¨ï¼ˆseq2seqï¼‰â€â¼€èŠ‚â¾¥ï¼Œè§£ç å™¨åœ¨å„ä¸ªæ—¶é—´æ­¥ä¾èµ–ç›¸åŒçš„èƒŒæ™¯å˜é‡ï¼ˆcontext vectorï¼‰æ¥è·å–è¾“â¼Šåºåˆ—ä¿¡æ¯ã€‚å½“ç¼–ç å™¨ä¸ºå¾ªç¯ç¥ç»â½¹ç»œæ—¶ï¼ŒèƒŒæ™¯å˜é‡æ¥â¾ƒå®ƒæœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚å°†æºåºåˆ—è¾“å…¥ä¿¡æ¯ä»¥å¾ªç¯å•ä½çŠ¶æ€ç¼–ç ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è§£ç å™¨ä»¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚ç„¶è€Œè¿™ç§ç»“æ„å­˜åœ¨ç€é—®é¢˜ï¼Œå°¤å…¶æ˜¯RNNæœºåˆ¶å®é™…ä¸­å­˜åœ¨é•¿ç¨‹æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå¯¹äºè¾ƒé•¿çš„å¥å­ï¼Œæˆ‘ä»¬å¾ˆéš¾å¯„å¸Œæœ›äºå°†è¾“å…¥çš„åºåˆ—è½¬åŒ–ä¸ºå®šé•¿çš„å‘é‡è€Œä¿å­˜æ‰€æœ‰çš„æœ‰æ•ˆä¿¡æ¯ï¼Œæ‰€ä»¥éšç€æ‰€éœ€ç¿»è¯‘å¥å­çš„é•¿åº¦çš„å¢åŠ ï¼Œè¿™ç§ç»“æ„çš„æ•ˆæœä¼šæ˜¾è‘—ä¸‹é™ã€‚\n",
    "\n",
    "ä¸æ­¤åŒæ—¶ï¼Œè§£ç çš„ç›®æ ‡è¯è¯­å¯èƒ½åªä¸åŸè¾“å…¥çš„éƒ¨åˆ†è¯è¯­æœ‰å…³ï¼Œè€Œå¹¶ä¸æ˜¯ä¸æ‰€æœ‰çš„è¾“å…¥æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œå½“æŠŠâ€œHello worldâ€ç¿»è¯‘æˆâ€œBonjour le mondeâ€æ—¶ï¼Œâ€œHelloâ€æ˜ å°„æˆâ€œBonjourâ€ï¼Œâ€œworldâ€æ˜ å°„æˆâ€œmondeâ€ã€‚åœ¨seq2seqæ¨¡å‹ä¸­ï¼Œè§£ç å™¨åªèƒ½éšå¼åœ°ä»ç¼–ç å™¨çš„æœ€ç»ˆçŠ¶æ€ä¸­é€‰æ‹©ç›¸åº”çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å°†è¿™ç§é€‰æ‹©è¿‡ç¨‹æ˜¾å¼åœ°å»ºæ¨¡ã€‚\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5km4dwgf9.PNG?imageView2/0/w/960/h/960)\n",
    "\n",
    "## æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶\n",
    "\n",
    "Attention æ˜¯ä¸€ç§é€šç”¨çš„å¸¦æƒæ± åŒ–æ–¹æ³•ï¼Œè¾“å…¥ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼šè¯¢é—®ï¼ˆqueryï¼‰å’Œé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ã€‚$ğ¤_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘˜}, ğ¯_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘£}$. Query  $ğªâˆˆâ„^{ğ‘‘_ğ‘}$ , attention layerå¾—åˆ°è¾“å‡ºä¸valueçš„ç»´åº¦ä¸€è‡´ $ğ¨âˆˆâ„^{ğ‘‘_ğ‘£}$. å¯¹äºä¸€ä¸ªqueryæ¥è¯´ï¼Œattention layer ä¼šä¸æ¯ä¸€ä¸ªkeyè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶è¿›è¡Œæƒé‡çš„å½’ä¸€åŒ–ï¼Œè¾“å‡ºçš„å‘é‡$o$åˆ™æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œè€Œæ¯ä¸ªkeyè®¡ç®—çš„æƒé‡ä¸valueä¸€ä¸€å¯¹åº”ã€‚\n",
    "\n",
    "ä¸ºäº†è®¡ç®—è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•°$\\alpha$ ç”¨äºè®¡ç®—queryå’Œkeyçš„ç›¸ä¼¼æ€§ï¼Œç„¶åå¯ä»¥è®¡ç®—æ‰€æœ‰çš„ attention scores $a_1, \\ldots, a_n$ by\n",
    "\n",
    "\n",
    "$$\n",
    "a_i = \\alpha(\\mathbf q, \\mathbf k_i).\n",
    "$$\n",
    "\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ softmaxå‡½æ•° è·å¾—æ³¨æ„åŠ›æƒé‡ï¼š\n",
    "\n",
    "\n",
    "$$\n",
    "b_1, \\ldots, b_n = \\textrm{softmax}(a_1, \\ldots, a_n).\n",
    "$$\n",
    "\n",
    "\n",
    "æœ€ç»ˆçš„è¾“å‡ºå°±æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼š\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf o = \\sum_{i=1}^n b_i \\mathbf v_i.\n",
    "$$\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5km4ooyu2.PNG?imageView2/0/w/960/h/960)\n",
    "\n",
    "ä¸åŒçš„attetion layerçš„åŒºåˆ«åœ¨äºscoreå‡½æ•°çš„é€‰æ‹©ï¼Œåœ¨æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸¤ä¸ªå¸¸ç”¨çš„æ³¨æ„å±‚ Dot-product Attention å’Œ Multilayer Perceptron Attentionï¼›éšåæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªå¼•å…¥attentionçš„seq2seqæ¨¡å‹å¹¶åœ¨è‹±æ³•ç¿»è¯‘è¯­æ–™ä¸Šè¿›è¡Œè®­ç»ƒä¸æµ‹è¯•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "graffitiCellId": "id_lyizjfl",
    "id": "2D4703A032B741F68676C00CF5B06CAF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "graffitiCellId": "id_ucnczrs",
    "id": "60B68D50106A4FBD9CA3C2B863146405",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs []\n",
      "files ['_about.txt', 'fra.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def file_name_walk(file_dir):\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "#         print(\"root\", root)  # å½“å‰ç›®å½•è·¯å¾„\n",
    "         print(\"dirs\", dirs)  # å½“å‰è·¯å¾„ä¸‹æ‰€æœ‰å­ç›®å½•\n",
    "         print(\"files\", files)  # å½“å‰è·¯å¾„ä¸‹æ‰€æœ‰éç›®å½•å­æ–‡ä»¶\n",
    "\n",
    "file_name_walk(\"/home/kesci/input/fraeng6506\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_bimjldk",
    "id": "4C277595040B4A0689320409E624C366",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Softmaxå±è”½\n",
    "åœ¨æ·±å…¥ç ”ç©¶å®ç°ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»softmaxæ“ä½œç¬¦çš„ä¸€ä¸ªå±è”½æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "graffitiCellId": "id_39i6msf",
    "id": "CD9DB3F8099F49FB886E0B5029173F44",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SequenceMask(X, X_len,value=-1e6):\n",
    "    maxlen = X.size(1)\n",
    "    #print(X.size(),torch.arange((maxlen),dtype=torch.float)[None, :],'\\n',X_len[:, None] )\n",
    "    mask = torch.arange((maxlen),dtype=torch.float)[None, :] >= X_len[:, None]   \n",
    "    # print(mask)\n",
    "    X[mask]=value\n",
    "    # print(value)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9242CA9E7BEB457A83FEDB994E53B381",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       1, -1000000, -1000000],\n",
       "        [       4,        5, -1000000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1,2,3], [4,5,6]])\n",
    "SequenceMask(X,torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "graffitiCellId": "id_mlvtr3b",
    "id": "B0BE96AC54A940878423D3C201ED8477",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_length):\n",
    "    # X: 3-D tensor, valid_length: 1-D or 2-D tensor\n",
    "    softmax = nn.Softmax(dim=-1)# è½¬åŒ–ä¸ºdim+input.dim()+1å› ä¸ºdim = -1\n",
    "    if valid_length is None:\n",
    "        return softmax(X)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_length.dim() == 1:\n",
    "            # print(1)\n",
    "            try:\n",
    "                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
    "            except:\n",
    "                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[1], axis=0))#[2,2,3,3]\n",
    "        else:\n",
    "            valid_length = valid_length.reshape((-1,))\n",
    "        # fill masked elements with a large negative, whose exp is 0\n",
    "        X = SequenceMask(X.reshape((-1, shape[-1])), valid_length)\n",
    " \n",
    "        return softmax(X).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "graffitiCellId": "id_gjfsirw",
    "id": "2DC35416E322461FB2B9FDD6E0379A02",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3476, 0.6593, 0.8059, 0.0851],\n",
      "         [0.3042, 0.4391, 0.2876, 0.7432]],\n",
      "\n",
      "        [[0.8875, 0.0104, 0.1835, 0.7056],\n",
      "         [0.0315, 0.3148, 0.4189, 0.1169]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4227, 0.5773, 0.0000, 0.0000],\n",
       "         [0.4663, 0.5337, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5234, 0.2177, 0.2589, 0.0000],\n",
       "         [0.2631, 0.3493, 0.3876, 0.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_test = torch.rand((2,2,4),dtype=torch.float)\n",
    "print(number_test)\n",
    "masked_softmax(number_test, torch.FloatTensor([2,3]))\n",
    "# è¿™é‡Œæ˜¯å¯¹äºdim=2è¿›è¡Œsoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_s7xh1br",
    "id": "6E17FB479C8E461185DC7E64B3B51A5D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**è¶…å‡º2ç»´çŸ©é˜µçš„ä¹˜æ³•** \n",
    "\n",
    "$X$ å’Œ $Y$ æ˜¯ç»´åº¦åˆ†åˆ«ä¸º$(b,n,m)$ å’Œ$(b, m, k)$çš„å¼ é‡ï¼Œè¿›è¡Œ $b$ æ¬¡äºŒç»´çŸ©é˜µä¹˜æ³•åå¾—åˆ° $Z$, ç»´åº¦ä¸º $(b, n, k)$ã€‚\n",
    "\n",
    "\n",
    "$$\n",
    " Z[i,:,:] = dot(X[i,:,:], Y[i,:,:])\\qquad for\\ i= 1,â€¦,n\\ .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "graffitiCellId": "id_c01uiu4",
    "id": "55C627C9AD274B3AA4366F554A7A33C8",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3.]],\n",
       "\n",
       "        [[3., 3.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.ones((2,1,3), dtype = torch.float), torch.ones((2,3,2), dtype = torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_5l05rc9",
    "id": "BB8410C97D6143F4885BFA00C8564260",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ç‚¹ç§¯æ³¨æ„åŠ›\n",
    "The dot product å‡è®¾queryå’Œkeysæœ‰ç›¸åŒçš„ç»´åº¦, å³ $\\forall i, ğª,ğ¤_ğ‘– âˆˆ â„_ğ‘‘ $. é€šè¿‡è®¡ç®—queryå’Œkeyè½¬ç½®çš„ä¹˜ç§¯æ¥è®¡ç®—attention score,é€šå¸¸è¿˜ä¼šé™¤å» $\\sqrt{d}$ å‡å°‘è®¡ç®—å‡ºæ¥çš„scoreå¯¹ç»´åº¦ğ‘‘çš„ä¾èµ–æ€§ï¼Œå¦‚ä¸‹\n",
    "\n",
    "\n",
    "$$\n",
    "ğ›¼(ğª,ğ¤)=âŸ¨ğª,ğ¤âŸ©/ \\sqrt{d} \n",
    "$$\n",
    "\n",
    "å‡è®¾ $ ğâˆˆâ„^{ğ‘šÃ—ğ‘‘}$ æœ‰ $m$ ä¸ªqueryï¼Œ$ğŠâˆˆâ„^{ğ‘›Ã—ğ‘‘}$ æœ‰ $n$ ä¸ªkeys. æˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ©é˜µè¿ç®—çš„æ–¹å¼è®¡ç®—æ‰€æœ‰ $mn$ ä¸ªscoreï¼š\n",
    "\n",
    "\n",
    "$$\n",
    "ğ›¼(ğ,ğŠ)=ğğŠ^ğ‘‡/\\sqrt{d}\n",
    "$$\n",
    " \n",
    "ç°åœ¨è®©æˆ‘ä»¬å®ç°è¿™ä¸ªå±‚ï¼Œå®ƒæ”¯æŒä¸€æ‰¹æŸ¥è¯¢å’Œé”®å€¼å¯¹ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒä½œä¸ºæ­£åˆ™åŒ–éšæœºåˆ é™¤ä¸€äº›æ³¨æ„åŠ›æƒé‡."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "graffitiCellId": "id_qpr6dwm",
    "id": "3CB825EFC83C4F7892F0ED1D4038FB49",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to the d2l package.\n",
    "class DotProductAttention(nn.Module): \n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # query: (batch_size, #queries, d)2,1,2\n",
    "    # key: (batch_size, #kv_pairs, d)2,10,2\n",
    "    # value: (batch_size, #kv_pairs, dim_v)2,10,4\n",
    "    # valid_length: either (batch_size, ) or (batch_size, xx)\n",
    "    def forward(self, query, key, value, valid_length=None):\n",
    "        d = query.shape[-1]\n",
    "        # set transpose_b=True to swap the last two dimensions of key\n",
    "        # å°å‹äºŒç»´çŸ©é˜µçš„è½¬ç½®,å°±æ˜¯x,yç›¸ä¹˜,è¿™é‡Œçš„xå°±æ˜¯1,yå°±æ˜¯2\n",
    "        # key.transpose(1,2)è¡Œåˆ—äº’æ¢,è½¬ç½®2,2,10\n",
    "        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_length))# æ³¨æ„2,1,10\n",
    "        #print(attention_weights.shape)\n",
    "        print(\"attention_weight\\n\",attention_weights)\n",
    "        return torch.bmm(attention_weights, value)#ç‚¹ä¹˜å¾—åˆ°æ³¨æ„åŠ›ï½—ï½…ï½‰ï½‡ï½ˆï½”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_sy1n984",
    "id": "CD3484D8F62449C08842C768228EA444",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### æµ‹è¯•\n",
    "ç°åœ¨æˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªæ‰¹ï¼Œæ¯ä¸ªæ‰¹æœ‰ä¸€ä¸ªqueryå’Œ10ä¸ªkey-valueså¯¹ã€‚æˆ‘ä»¬é€šè¿‡valid_lengthæŒ‡å®šï¼Œå¯¹äºç¬¬ä¸€æ‰¹ï¼Œæˆ‘ä»¬åªå…³æ³¨å‰2ä¸ªé”®-å€¼å¯¹ï¼Œè€Œå¯¹äºç¬¬äºŒæ‰¹ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥å‰6ä¸ªé”®-å€¼å¯¹ã€‚å› æ­¤ï¼Œå°½ç®¡è¿™ä¸¤ä¸ªæ‰¹å¤„ç†å…·æœ‰ç›¸åŒçš„æŸ¥è¯¢å’Œé”®å€¼å¯¹ï¼Œä½†æˆ‘ä»¬è·å¾—çš„è¾“å‡ºæ˜¯ä¸åŒçš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "graffitiCellId": "id_rt2wg6w",
    "id": "DF454887CCD745858E6505AF13119489",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weight\n",
      " tensor([[[0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten = DotProductAttention(dropout=0)#ä¸åˆ é™¤ï¼Œåˆå§‹åŒ–\n",
    "\n",
    "keys = torch.ones((2,10,2),dtype=torch.float)\n",
    "#print(keys.shape)2,10,2\n",
    "values = torch.arange((40), dtype=torch.float).view(1,10,4).repeat(2,1,1)# å¤åˆ¶ä¸€ä»½\n",
    "#print(values.shape)2,10,4\n",
    "# print(values)\n",
    "atten(torch.ones((2,1,2),dtype=torch.float), keys, values, torch.FloatTensor([2, 6]))# ç¬¬ä¸€ä¸ªæ˜¯å…³æ³¨\n",
    "#print(atten(torch.ones((2,1,2),dtype=torch.float), keys, values, torch.FloatTensor([2, 6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_vqmu7c7",
    "id": "AD0E0FB0D571413E8DE3796462784DD4",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›\n",
    "åœ¨å¤šå±‚æ„ŸçŸ¥å™¨ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°† query and keys æŠ•å½±åˆ°  $â„^â„$ .ä¸ºäº†æ›´å…·ä½“ï¼Œæˆ‘ä»¬å°†å¯ä»¥å­¦ä¹ çš„å‚æ•°åšå¦‚ä¸‹æ˜ å°„ \n",
    "$ğ–_ğ‘˜âˆˆâ„^{â„Ã—ğ‘‘_ğ‘˜}$ ,  $ğ–_ğ‘âˆˆâ„^{â„Ã—ğ‘‘_ğ‘}$ , and  $ğ¯âˆˆâ„^h$ . å°†scoreå‡½æ•°å®šä¹‰\n",
    "$$\n",
    "ğ›¼(ğ¤,ğª)=ğ¯^ğ‘‡tanh(ğ–_ğ‘˜ğ¤+ğ–_ğ‘ğª)\n",
    "$$\n",
    ". \n",
    "ç„¶åå°†key å’Œ value åœ¨ç‰¹å¾çš„ç»´åº¦ä¸Šåˆå¹¶ï¼ˆconcatenateï¼‰ï¼Œç„¶åé€è‡³ a single hidden layer perceptron è¿™å±‚ä¸­ hidden layer ä¸º  â„  and è¾“å‡ºçš„sizeä¸º 1 .éšå±‚æ¿€æ´»å‡½æ•°ä¸ºtanhï¼Œæ— åç½®."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "graffitiCellId": "id_2pmvrcv",
    "id": "047BD3F3C6DF46AC8C0FBAFF61F34B75",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to the d2l package.å¤šå±‚æ„ŸçŸ¥æœº\n",
    "class MLPAttention(nn.Module):  \n",
    "    def __init__(self, units,ipt_dim,dropout, **kwargs):\n",
    "        super(MLPAttention, self).__init__(**kwargs)\n",
    "        # Use flatten=True to keep query's and key's 3-D shapes.ipt_dim=2,units = 8, dropout=0\n",
    "        self.W_k = nn.Linear(ipt_dim, units, bias=False)# h*d\n",
    "        self.W_q = nn.Linear(ipt_dim, units, bias=False)# h*d\n",
    "        self.v = nn.Linear(units, 1, bias=False)# h\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, valid_length):\n",
    "        query, key = self.W_k(query), self.W_q(key)#\n",
    "        #print(\"size\",query.size(),key.size()) 2,1,8 || 2,10,8\n",
    "        # expand query to (batch_size, #querys, 1, units), and key to\n",
    "        # (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.\n",
    "        # torch.squeeze() è¿™ä¸ªå‡½æ•°ä¸»è¦å¯¹æ•°æ®çš„ç»´åº¦è¿›è¡Œå‹ç¼©ï¼Œå»æ‰ç»´æ•°ä¸º1çš„çš„ç»´åº¦\n",
    "        # torch.unsqueeze()è¿™ä¸ªå‡½æ•°ä¸»è¦æ˜¯å¯¹æ•°æ®ç»´åº¦è¿›è¡Œæ‰©å……ã€‚ç»™æŒ‡å®šä½ç½®åŠ ä¸Šç»´æ•°ä¸ºä¸€çš„ç»´åº¦\n",
    "        # print(query.unsqueeze(2).shape,key.unsqueeze(1).shape)\n",
    "        features = query.unsqueeze(2) + key.unsqueeze(1)# å¹¿æ’­æœºåˆ¶\n",
    "        # un\n",
    "        #print(\"features:\",features.size())  #--------------å¼€å¯\n",
    "        scores = self.v(features).squeeze(-1) \n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
    "        return torch.bmm(attention_weights, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_o2cxg9q",
    "id": "40A0160DE63247F881553CC224705D7A",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### æµ‹è¯•\n",
    "å°½ç®¡MLPAttentionåŒ…å«ä¸€ä¸ªé¢å¤–çš„MLPæ¨¡å‹ï¼Œä½†å¦‚æœç»™å®šç›¸åŒçš„è¾“å…¥å’Œç›¸åŒçš„é”®ï¼Œæˆ‘ä»¬å°†è·å¾—ä¸DotProductAttentionç›¸åŒçš„è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "graffitiCellId": "id_ji2koe2",
    "id": "A399CB39F56241048E63FFD6FD3E3AE9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten = MLPAttention(ipt_dim=2,units = 8, dropout=0)\n",
    "# print(keys.shape)\n",
    "atten(torch.ones((2,1,2), dtype = torch.float), keys, values, torch.FloatTensor([2, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_qqem3ml",
    "id": "C4CD9496F89B418F9420B4ECD6DE4A60",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# æ€»ç»“\n",
    "\n",
    "- æ³¨æ„åŠ›å±‚æ˜¾å¼åœ°é€‰æ‹©ç›¸å…³çš„ä¿¡æ¯ã€‚\n",
    "- æ³¨æ„å±‚çš„å†…å­˜ç”±é”®-å€¼å¯¹ç»„æˆï¼Œå› æ­¤å®ƒçš„è¾“å‡ºæ¥è¿‘äºé”®ç±»ä¼¼äºæŸ¥è¯¢çš„å€¼ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_1b80ob1",
    "id": "28BBCA401DCC416385D179EC8A706DE6",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹\n",
    "\n",
    "æœ¬èŠ‚ä¸­å°†æ³¨æ„æœºåˆ¶æ·»åŠ åˆ°sequence to sequence æ¨¡å‹ä¸­ï¼Œä»¥æ˜¾å¼åœ°ä½¿ç”¨æƒé‡èšåˆstatesã€‚ä¸‹å›¾å±•ç¤ºencoding å’Œdecodingçš„æ¨¡å‹ç»“æ„ï¼Œåœ¨æ—¶é—´æ­¥ä¸ºtçš„æ—¶å€™ã€‚æ­¤åˆ»attention layerä¿å­˜ç€encoderingçœ‹åˆ°çš„æ‰€æœ‰ä¿¡æ¯â€”â€”å³encodingçš„æ¯ä¸€æ­¥è¾“å‡ºã€‚åœ¨decodingé˜¶æ®µï¼Œè§£ç å™¨çš„$t$æ—¶åˆ»çš„éšè—çŠ¶æ€è¢«å½“ä½œqueryï¼Œencoderçš„æ¯ä¸ªæ—¶é—´æ­¥çš„hidden statesä½œä¸ºkeyå’Œvalueè¿›è¡Œattentionèšåˆ. Attetion modelçš„è¾“å‡ºå½“ä½œæˆä¸Šä¸‹æ–‡ä¿¡æ¯context vectorï¼Œå¹¶ä¸è§£ç å™¨è¾“å…¥$D_t$æ‹¼æ¥èµ·æ¥ä¸€èµ·é€åˆ°è§£ç å™¨ï¼š\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800)\n",
    "\n",
    "$$\n",
    "Fig1å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹è§£ç çš„ç¬¬äºŒæ­¥\n",
    "$$\n",
    "\n",
    "\n",
    "ä¸‹å›¾å±•ç¤ºäº†seq2seqæœºåˆ¶çš„æ‰€ä»¥å±‚çš„å…³ç³»ï¼Œä¸‹é¢å±•ç¤ºäº†encoderå’Œdecoderçš„layerç»“æ„\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800)\n",
    "\n",
    "$$\n",
    "Fig2å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹ä¸­å±‚ç»“æ„\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "graffitiCellId": "id_xbbsd1x",
    "id": "5F439000597B4D638C3C6A85BA82A82D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/kesci/input/d2len9900')\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_9bq3vbt",
    "id": "FBF33B6F0ABC45A497E1C94A67392499",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## è§£ç å™¨\n",
    "   ç”±äºå¸¦æœ‰æ³¨æ„æœºåˆ¶çš„seq2seqçš„ç¼–ç å™¨ä¸ä¹‹å‰ç« èŠ‚ä¸­çš„Seq2SeqEncoderç›¸åŒï¼Œæ‰€ä»¥åœ¨æ­¤å¤„æˆ‘ä»¬åªå…³æ³¨è§£ç å™¨ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªMLPæ³¨æ„å±‚(MLPAttention)ï¼Œå®ƒçš„éšè—å¤§å°ä¸è§£ç å™¨ä¸­çš„LSTMå±‚ç›¸åŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡ä»ç¼–ç å™¨ä¼ é€’ä¸‰ä¸ªå‚æ•°æ¥åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€:\n",
    "   \n",
    "- the encoder outputs of all timestepsï¼šencoderè¾“å‡ºçš„å„ä¸ªçŠ¶æ€ï¼Œè¢«ç”¨äºattetion layerçš„memoryéƒ¨åˆ†ï¼Œæœ‰ç›¸åŒçš„keyå’Œvalues,$H_t$æ—¶é—´åºåˆ—çš„éšè—çŠ¶æ€\n",
    "- the hidden state of the encoderâ€™s final timestepï¼šç¼–ç å™¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œè¢«ç”¨äºåˆå§‹åŒ–decoder çš„hidden state\n",
    "\n",
    "\n",
    "- the encoder valid length: ç¼–ç å™¨çš„æœ‰æ•ˆé•¿åº¦ï¼Œå€Ÿæ­¤ï¼Œæ³¨æ„å±‚ä¸ä¼šè€ƒè™‘ç¼–ç å™¨è¾“å‡ºä¸­çš„å¡«å……æ ‡è®°ï¼ˆPaddingsï¼‰\n",
    "\n",
    "\n",
    "   åœ¨è§£ç çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è§£ç å™¨çš„æœ€åä¸€ä¸ªRNNå±‚çš„è¾“å‡ºä½œä¸ºæ³¨æ„å±‚çš„queryã€‚ç„¶åï¼Œå°†æ³¨æ„åŠ›æ¨¡å‹çš„è¾“å‡ºä¸è¾“å…¥åµŒå…¥å‘é‡è¿æ¥èµ·æ¥ï¼Œè¾“å…¥åˆ°RNNå±‚ã€‚è™½ç„¶RNNå±‚éšè—çŠ¶æ€ä¹ŸåŒ…å«æ¥è‡ªè§£ç å™¨çš„å†å²ä¿¡æ¯ï¼Œä½†æ˜¯attention modelçš„è¾“å‡ºæ˜¾å¼åœ°é€‰æ‹©äº†enc_valid_lenä»¥å†…çš„ç¼–ç å™¨è¾“å‡ºï¼Œè¿™æ ·attentionæœºåˆ¶å°±ä¼šå°½å¯èƒ½æ’é™¤å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "graffitiCellId": "id_n3xn2jo",
    "id": "421CF4D81A7E43378AF5C53236DC0586",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(d2l.Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)# åˆå§‹åŒ–\n",
    "        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)# éšè—å±‚\n",
    "        # æ³¨æ„ç»†èƒ\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_len, *args):\n",
    "        # encoderå±‚è¾“å‡º:output,éšè—å±‚çŠ¶æ€,æœ‰æ•ˆè—æ¯’\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        # print(\"output shape is {}\".format(outputs.shape))\n",
    "        # print(\"output shape is {}\".format(outputs.permute(1,0,-1).shape))\n",
    "#         print(\"first:\",outputs.size(),hidden_state[0].size(),hidden_state[1].size())\n",
    "        # Transpose outputs to (batch_size, seq_len, hidden_size)\n",
    "        return (outputs.permute(1,0,-1), hidden_state, enc_valid_len)\n",
    "        # å› ä¸ºæ¯ä¸ªè¯è¯­,ä¹Ÿå°±æ˜¯æ¯ä¸ªå•ç”¨8\n",
    "        #outputs.swapaxes(0, 1)\n",
    "        \n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, hidden_state, enc_valid_len = state\n",
    "        #(\"X.size\",X.size())\n",
    "        #print(self.embedding(X).shape)\n",
    "        X = self.embedding(X).transpose(0,1)\n",
    "        #print(\"Xembeding.size2\",X.size())\n",
    "        outputs = []\n",
    "        for l, x in enumerate(X):\n",
    "#             print(f\"\\n{l}-th token\")\n",
    "#             print(\"x.first.size()\",x.size())\n",
    "            # query shape: (batch_size, 1, hidden_size)\n",
    "            # select hidden state of the last rnn layer as query\n",
    "            query = hidden_state[0][-1].unsqueeze(1) # np.expand_dims(hidden_state[0][-1], axis=1)\n",
    "            # context has same shape as query\n",
    "#             print(\"query enc_outputs, enc_outputs:\\n\",query.size(), enc_outputs.size(), enc_outputs.size())\n",
    "            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)\n",
    "            # Concatenate on the feature dimension\n",
    "#             print(\"context.size:\",context.size())\n",
    "            x = torch.cat((context, x.unsqueeze(1)), dim=-1)\n",
    "            # Reshape x to (1, batch_size, embed_size+hidden_size)\n",
    "#             print(\"rnn\",x.size(), len(hidden_state))\n",
    "            out, hidden_state = self.rnn(x.transpose(0,1), hidden_state)\n",
    "            outputs.append(out)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.transpose(0, 1), [enc_outputs, hidden_state,\n",
    "                                        enc_valid_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_wbihjkp",
    "id": "CA550D7B430D4907857B054FC17C77ED",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥ç”¨æ³¨æ„åŠ›æ¨¡å‹æ¥æµ‹è¯•seq2seqã€‚ä¸ºäº†ä¸ç¬¬9.7èŠ‚ä¸­çš„æ¨¡å‹ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬å¯¹vocab_sizeã€embed_sizeã€num_hiddenså’Œnum_layersä½¿ç”¨ç›¸åŒçš„è¶…å‚æ•°ã€‚ç»“æœï¼Œæˆ‘ä»¬å¾—åˆ°äº†ç›¸åŒçš„è§£ç å™¨è¾“å‡ºå½¢çŠ¶ï¼Œä½†æ˜¯çŠ¶æ€ç»“æ„æ”¹å˜äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "graffitiCellId": "id_5u9j8bu",
    "id": "4CCF2FAC8DE741D2B86E509FFA6F33DB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size=4\n",
      "seq_length=7\n",
      "hidden dim=16\n",
      "num_layers=2\n",
      "\n",
      "encoder output size: torch.Size([7, 4, 16])\n",
      "encoder hidden size: torch.Size([2, 4, 16])\n",
      "encoder memory size: torch.Size([2, 4, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = d2l.Seq2SeqEncoder(vocab_size=10, embed_size=8,\n",
    "                            num_hiddens=16, num_layers=2)#è¯å…¸ï¼‘ï¼ä¸ª,æ¯ä¸ªé•¿åº¦ä¸º8,éšè—16ä¸ª,lstmä¸¤å±‚\n",
    "# encoder.initialize()\n",
    "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8,\n",
    "                                  num_hiddens=16, num_layers=2)\n",
    "X = torch.zeros((4, 7),dtype=torch.long)# 4ä¸ªå¥å­,æ¯ä¸ªå¥å­7ä¸ªå•è¯,ä½†æ˜¯åˆ°åé¢ä¼šè½¬ç½®\n",
    "print(\"batch size=4\\nseq_length=7\\nhidden dim=16\\nnum_layers=2\\n\")\n",
    "# batch size=4\n",
    "# seq_length=7\n",
    "# hidden dim=16\n",
    "# num_layers=2\n",
    "print('encoder output size:', encoder(X)[0].size())\n",
    "print('encoder hidden size:', encoder(X)[1][0].size())\n",
    "print('encoder memory size:', encoder(X)[1][1].size())\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "out, state = decoder(X, state)\n",
    "out.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_k53lcnp",
    "id": "25FB3334E1684E59966D79EA35B050D0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# è®­ç»ƒ\n",
    "\n",
    "  ä¸ç¬¬9.7.4èŠ‚ç›¸ä¼¼ï¼Œé€šè¿‡åº”ç”¨ç›¸åŒçš„è®­ç»ƒè¶…å‚æ•°å’Œç›¸åŒçš„è®­ç»ƒæŸå¤±æ¥å°è¯•ä¸€ä¸ªç®€å•çš„å¨±ä¹æ¨¡å‹ã€‚ä»ç»“æœä¸­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œç”±äºè®­ç»ƒæ•°æ®é›†ä¸­çš„åºåˆ—ç›¸å¯¹è¾ƒçŸ­ï¼Œé¢å¤–çš„æ³¨æ„å±‚å¹¶æ²¡æœ‰å¸¦æ¥æ˜¾è‘—çš„æ”¹è¿›ã€‚ç”±äºç¼–ç å™¨å’Œè§£ç å™¨çš„æ³¨æ„å±‚çš„è®¡ç®—å¼€é”€ï¼Œè¯¥æ¨¡å‹æ¯”æ²¡æœ‰æ³¨æ„çš„seq2seqæ¨¡å‹æ…¢å¾—å¤šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "graffitiCellId": "id_3uv6guo",
    "id": "6DC0F075B2EA4EA78B6D405A35D896CC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import torch\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from torch.utils import data\n",
    "import sys\n",
    "import collections\n",
    "# ä¸‹é¢è¿™äº›å‡½æ•°æ˜¯ä¸Šä¸€èŠ‚å†™å¥½çš„\n",
    "class Vocab(object): # This class is saved in d2l.\n",
    "  def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
    "    # sort by frequency and token\n",
    "    counter = collections.Counter(tokens)\n",
    "    token_freqs = sorted(counter.items(), key=lambda x: x[0])\n",
    "    token_freqs.sort(key=lambda x: x[1], reverse=True)\n",
    "    if use_special_tokens:\n",
    "      # padding, begin of sentence, end of sentence, unknown\n",
    "      self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
    "      tokens = ['', '', '', '']\n",
    "    else:\n",
    "      self.unk = 0\n",
    "      tokens = ['']\n",
    "    tokens += [token for token, freq in token_freqs if freq >= min_freq]\n",
    "    self.idx_to_token = []\n",
    "    self.token_to_idx = dict()\n",
    "    for token in tokens:\n",
    "      self.idx_to_token.append(token)\n",
    "      self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "      \n",
    "  def __len__(self):\n",
    "    return len(self.idx_to_token)\n",
    "  \n",
    "  def __getitem__(self, tokens):\n",
    "    if not isinstance(tokens, (list, tuple)):\n",
    "      return self.token_to_idx.get(tokens, self.unk)\n",
    "    else:\n",
    "      return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "  def to_tokens(self, indices):\n",
    "    if not isinstance(indices, (list, tuple)):\n",
    "      return self.idx_to_token[indices]\n",
    "    else:\n",
    "      return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "def load_data_nmt(batch_size, max_len, num_examples=1000):\n",
    "    \"\"\"Download an NMT dataset, return its vocabulary and data iterator.\"\"\"\n",
    "    # Download and preprocess\n",
    "    def preprocess_raw(text):\n",
    "        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "        out = ''\n",
    "        for i, char in enumerate(text.lower()):\n",
    "            if char in (',', '!', '.') and text[i-1] != ' ':\n",
    "                out += ' '\n",
    "            out += char\n",
    "        return out \n",
    "\n",
    "\n",
    "    with open('/home/kesci/input/fraeng6506/fra.txt', 'r') as f:\n",
    "      raw_text = f.read()\n",
    "\n",
    "\n",
    "    text = preprocess_raw(raw_text)\n",
    "\n",
    "    # Tokenize\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if i >= num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) >= 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "\n",
    "    # Build vocab\n",
    "    def build_vocab(tokens):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        return Vocab(tokens, min_freq=3, use_special_tokens=True)\n",
    "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
    "\n",
    "    # Convert to index arrays\n",
    "    def pad(line, max_len, padding_token):\n",
    "        if len(line) > max_len:\n",
    "            return line[:max_len]\n",
    "        return line + [padding_token] * (max_len - len(line))\n",
    "\n",
    "    def build_array(lines, vocab, max_len, is_source):\n",
    "        lines = [vocab[line] for line in lines]\n",
    "        if not is_source:\n",
    "            lines = [[vocab.bos] + line + [vocab.eos] for line in lines]\n",
    "        array = torch.tensor([pad(line, max_len, vocab.pad) for line in lines])\n",
    "        valid_len = (array != vocab.pad).sum(1)\n",
    "        return array, valid_len\n",
    "\n",
    "    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n",
    "    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)\n",
    "    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False)\n",
    "    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    return src_vocab, tgt_vocab, train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "graffitiCellId": "id_uwt29qm",
    "id": "16B6DBF49DE6462CB969E7FEB2B80EA4",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, ctx = 0.005, 500, d2l.try_gpu()\n",
    "\n",
    "src_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size, num_steps)\n",
    "encoder = d2l.Seq2SeqEncoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(\n",
    "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = d2l.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_l19wr5o",
    "id": "B087A130ADCD4C6A855201B68C1B437F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## è®­ç»ƒå’Œé¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "graffitiCellId": "id_l50r9v2",
    "id": "C85DB18574124B778FF37F0C939A87CF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   50,loss 0.098, time 41.8 sec\n",
      "epoch  100,loss 0.046, time 41.9 sec\n",
      "epoch  150,loss 0.032, time 41.9 sec\n",
      "epoch  200,loss 0.027, time 41.9 sec\n",
      "epoch  250,loss 0.028, time 42.3 sec\n",
      "epoch  300,loss 0.024, time 42.3 sec\n",
      "epoch  350,loss 0.024, time 42.0 sec\n",
      "epoch  400,loss 0.024, time 42.5 sec\n",
      "epoch  450,loss 0.023, time 45.6 sec\n",
      "epoch  500,loss 0.023, time 42.1 sec\n"
     ]
    }
   ],
   "source": [
    "d2l.train_s2s_ch9(model, train_iter, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "graffitiCellId": "id_fgsubff",
    "id": "59CD0BDF632440938BF388ACCD017A09",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go . => va !\n",
      "Good Night ! => Ã  pas  .\n",
      "I'm OK . => je vais bien .\n",
      "I won ! => je l'ai emportÃ© !\n"
     ]
    }
   ],
   "source": [
    "for sentence in ['Go .', 'Good Night !', \"I'm OK .\", 'I won !']:\n",
    "    print(sentence + ' => ' + d2l.predict_s2s_ch9(\n",
    "        model, sentence, src_vocab, tgt_vocab, num_steps, ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2400C61CD3824675A36DED3276312263",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/kesci/work', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/papermill-7.7.7-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/tenacity-6.0.0-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/nbformat-4.4.0-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/future-0.18.2-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/Click-7.0-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/ansiwrap-0.8.4-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/defusedxml-0.6.0-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/pandocfilters-1.4.2-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/ipython_genutils-0.2.0-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/textwrap3-0.9.2-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/webencodings-0.5.1-py3.7.egg', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/home/kesci/.ipython', '/home/kesci/input/d2len9900']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "E550D3030FC742378D05C6A7EB748194",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9951FB186D42498485211DEC7D223D8D",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
