{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3813, -1.1712, -0.4844,  1.3131,  1.6718])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0025,  0.0006, -0.0007,  0.0029,  0.0037])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.random.normal(0, 0.01, size=(5)),\n",
    "                       dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(random.choice([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 2.5000], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[2,3]],dtype=float)\n",
    "print((a!=0).sum(0))\n",
    "a.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201  48 129 221 251 246  50 194  91  61  98  87  15  18  36  95   3 149\n",
      " 131 137 149 121  83 247 237 169  79 167 246 113 130 214 171  93  84  63\n",
      " 152 248 105 130 102 209 204 245 175  42 153  32 203  37 143 153  87 233\n",
      "  58 183 229 182 204  16  72 179 228 188 161 200  52  68   4 194  94 243\n",
      " 210 240  43  70 237 139 164 214 251 107 234 121 246 207 191 236 229 119\n",
      " 216 238 220 137  34   5  68 184  63  37 202 152 219 188 162  40 237 207\n",
      " 127 148 230 110 147  79 120 243 138 140 215 146  26 154 249  49 136  17\n",
      " 134 227 235 242   1 208 104   7 254  42 196 245 160  41 231 183 122 140\n",
      "  12 130   3 241 228 202 182 215 153 158 224 217  98 243 195 111  92  92\n",
      " 169 159  91 232  34 253 218 171  53 149 226  74  33 143 161 230 135 159\n",
      "  13  86 252 212  47 127 198  10  91 162  89   3  69  23 128   5  43 236\n",
      "  55  55   4  20 158 239 221 121 115 114   9 132 125 168  96  49 199  55\n",
      " 236 218 109 112 145 206  35 222 220  57 173 233 227 116 127  21  75 108\n",
      " 181  14  57 188  40  10   0 217  32   0 248   1 139  23 177  80  33 134\n",
      " 145  30 233  55  10 107 128   3  80 223 149  89 216 150 145   2 170 138\n",
      " 138 104 146 169 198 218 141 248  58 115   0 108 199 205  31  83 135 249\n",
      "  39 102 217 171 211 209 135  29  87  25  37 122]\n",
      "(10, 10, 3)\n",
      "tensor([[[201, 221,  50,  61,  15,  95, 131, 121, 237, 167],\n",
      "         [130,  93, 152, 130, 204,  42, 203, 153,  58, 182],\n",
      "         [ 72, 188,  52, 194, 210,  70, 164, 107, 246, 236],\n",
      "         [216, 137,  68,  37, 219,  40, 127, 110, 120, 140],\n",
      "         [ 26,  49, 134, 242, 104,  42, 160, 183,  12, 241],\n",
      "         [182, 158,  98, 111, 169, 232, 218, 149,  33, 230],\n",
      "         [ 13, 212, 198, 162,  69,   5,  55,  20, 221, 114],\n",
      "         [125,  49, 236, 112,  35,  57, 227,  21, 181, 188],\n",
      "         [  0,   0, 139,  80, 145,  55, 128, 223, 216,   2],\n",
      "         [138, 169, 141, 115, 199,  83,  39, 171, 135,  25]],\n",
      "\n",
      "        [[ 48, 251, 194,  98,  18,   3, 137,  83, 169, 246],\n",
      "         [214,  84, 248, 102, 245, 153,  37,  87, 183, 204],\n",
      "         [179, 161,  68,  94, 240, 237, 214, 234, 207, 229],\n",
      "         [238,  34, 184, 202, 188, 237, 148, 147, 243, 215],\n",
      "         [154, 136, 227,   1,   7, 196,  41, 122, 130, 228],\n",
      "         [215, 224, 243,  92, 159,  34, 171, 226, 143, 135],\n",
      "         [ 86,  47,  10,  89,  23,  43,  55, 158, 121,   9],\n",
      "         [168, 199, 218, 145, 222, 173, 116,  75,  14,  40],\n",
      "         [217, 248,  23,  33,  30,  10,   3, 149, 150, 170],\n",
      "         [104, 198, 248,   0, 205, 135, 102, 211,  29,  37]],\n",
      "\n",
      "        [[129, 246,  91,  87,  36, 149, 149, 247,  79, 113],\n",
      "         [171,  63, 105, 209, 175,  32, 143, 233, 229,  16],\n",
      "         [228, 200,   4, 243,  43, 139, 251, 121, 191, 119],\n",
      "         [220,   5,  63, 152, 162, 207, 230,  79, 138, 146],\n",
      "         [249,  17, 235, 208, 254, 245, 231, 140,   3, 202],\n",
      "         [153, 217, 195,  92,  91, 253,  53,  74, 161, 159],\n",
      "         [252, 127,  91,   3, 128, 236,   4, 239, 115, 132],\n",
      "         [ 96,  55, 109, 206, 220, 233, 127, 108,  57,  10],\n",
      "         [ 32,   1, 177, 134, 233, 107,  80,  89, 145, 138],\n",
      "         [146, 218,  58, 108,  31, 249, 217, 209,  87, 122]]])\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 255, size=300)\n",
    "print(data)\n",
    "img = data.reshape(10,10,3)\n",
    "print(img.shape)\n",
    "img_tensor = transforms.ToTensor()(img) # 转换成tensor\n",
    "print(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print((a!=1).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(1, 5, None)\n"
     ]
    }
   ],
   "source": [
    "print(slice(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.6733, -1.6786, -0.5462],\n",
      "         [ 1.2425, -0.1384,  1.5760]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,2,3)\n",
    "print(a)\n",
    "# print(a[slice(1,5),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4075,  0.5648,  0.3735, -0.4688, -1.2602,  0.7360, -1.2127,  0.3659,\n",
      "          2.2086, -1.1140,  1.1271],\n",
      "        [ 0.1354, -1.0377,  1.9350, -0.7969,  1.3153, -0.8429,  1.6227, -0.2585,\n",
      "         -1.0144, -0.3480,  0.7665],\n",
      "        [ 0.8499,  1.4345,  0.2676, -0.4927, -2.2076,  1.0837,  0.7890, -0.7827,\n",
      "         -0.4112,  0.0759, -0.5232],\n",
      "        [ 0.6127,  0.7109, -0.9012, -0.1604, -0.1981, -1.8700,  0.0192,  0.7330,\n",
      "         -0.0257,  1.3321,  1.0055]])\n"
     ]
    }
   ],
   "source": [
    "print(a[slice(1,5),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  = torch.Tensor([[1],[2]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(a.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.Tensor([1])\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6332, -1.5131,  1.3455, -1.6110, -1.7969, -2.5992, -0.1017,  0.8763,\n",
       "          0.9414, -1.9822, -0.1544]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,11)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 2]' is invalid for input of size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0240b04bbb3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 2]' is invalid for input of size 11"
     ]
    }
   ],
   "source": [
    "print(a.view(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor([1,2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's state_dict:\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "\n",
      "optimizer's state_dict\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139679427056976, 139679427057136, 139679427057216, 139679427057296, 139679427057376, 139679427057456, 139679427057536, 139679427057616, 139679427057696, 139679427057776]}]\n",
      "\n",
      "print particular param\n",
      "\n",
      " torch.Size([6, 3, 5, 5])\n",
      "\n",
      " Parameter containing:\n",
      "tensor([[[[ 0.0265, -0.0381,  0.0153, -0.0750, -0.1002],\n",
      "          [-0.0678,  0.0147,  0.0970, -0.0746, -0.1152],\n",
      "          [ 0.0539, -0.1077, -0.0172, -0.0991, -0.0557],\n",
      "          [-0.1027, -0.0461,  0.0893,  0.0209,  0.0136],\n",
      "          [-0.0815,  0.0931,  0.0794,  0.0136,  0.0173]],\n",
      "\n",
      "         [[ 0.0683,  0.0286,  0.0228,  0.0642, -0.0306],\n",
      "          [-0.0323,  0.0361,  0.0877, -0.0324,  0.0484],\n",
      "          [ 0.0706,  0.0300,  0.0676,  0.0806, -0.0651],\n",
      "          [ 0.0907,  0.0686, -0.0605, -0.0009,  0.0536],\n",
      "          [-0.0768, -0.0064,  0.0305,  0.0770, -0.0574]],\n",
      "\n",
      "         [[-0.1041,  0.0105,  0.0765,  0.0554, -0.0349],\n",
      "          [-0.1019, -0.0447,  0.1025,  0.0729, -0.0310],\n",
      "          [-0.0325, -0.0851,  0.0517,  0.0203, -0.0104],\n",
      "          [ 0.0601, -0.0495, -0.0774,  0.0911, -0.0049],\n",
      "          [-0.0137,  0.0828,  0.0131,  0.0922,  0.1013]]],\n",
      "\n",
      "\n",
      "        [[[-0.1116, -0.0457, -0.0129, -0.0805, -0.0920],\n",
      "          [ 0.0966, -0.0166, -0.0481,  0.0117, -0.0703],\n",
      "          [ 0.1045, -0.0490,  0.0523,  0.0973,  0.0412],\n",
      "          [-0.0617, -0.1028,  0.0891,  0.0777,  0.0883],\n",
      "          [ 0.0353, -0.0831, -0.0606, -0.1012, -0.1034]],\n",
      "\n",
      "         [[-0.0404,  0.0569, -0.0919, -0.0619,  0.1127],\n",
      "          [-0.0708, -0.0544, -0.0813, -0.0787,  0.0256],\n",
      "          [ 0.0795, -0.0789, -0.1110,  0.0184, -0.0255],\n",
      "          [ 0.0769,  0.0157,  0.0837, -0.0664, -0.0923],\n",
      "          [ 0.1027,  0.0785,  0.0722,  0.0323,  0.0907]],\n",
      "\n",
      "         [[ 0.0253,  0.0406,  0.0288,  0.0504, -0.0899],\n",
      "          [ 0.1047,  0.0710, -0.0721,  0.0210,  0.1035],\n",
      "          [ 0.0769,  0.0990, -0.0575,  0.1146,  0.0609],\n",
      "          [-0.0141, -0.0473,  0.0795,  0.0957, -0.0144],\n",
      "          [-0.0575, -0.0111, -0.0280, -0.0965, -0.0565]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0356,  0.0189,  0.0197,  0.0470,  0.0348],\n",
      "          [ 0.0541,  0.0808, -0.0097,  0.1122, -0.0925],\n",
      "          [ 0.0383, -0.0250, -0.0154,  0.0304, -0.0303],\n",
      "          [-0.0803,  0.0535,  0.0869,  0.0698,  0.0229],\n",
      "          [-0.0274, -0.0196,  0.0879,  0.0357, -0.0534]],\n",
      "\n",
      "         [[ 0.0657,  0.1060,  0.0067, -0.1076, -0.0744],\n",
      "          [-0.0677, -0.0328,  0.0579, -0.0127, -0.0019],\n",
      "          [ 0.0987,  0.0369, -0.0182,  0.0457, -0.0154],\n",
      "          [ 0.0055,  0.0968, -0.0014,  0.0245, -0.0449],\n",
      "          [-0.0429,  0.0969,  0.0665, -0.0551,  0.0029]],\n",
      "\n",
      "         [[ 0.0526, -0.0170, -0.0338, -0.1003, -0.0606],\n",
      "          [-0.0650, -0.0819, -0.0867, -0.0198, -0.0977],\n",
      "          [-0.0666, -0.0733,  0.1021,  0.0450,  0.0432],\n",
      "          [-0.1072, -0.0996, -0.0054, -0.0038,  0.0055],\n",
      "          [-0.0536,  0.0518,  0.0394, -0.0652, -0.0635]]],\n",
      "\n",
      "\n",
      "        [[[-0.0869,  0.0692, -0.0889,  0.0129, -0.0385],\n",
      "          [-0.0082,  0.0332,  0.0723,  0.0317, -0.1062],\n",
      "          [ 0.0040,  0.1116, -0.0274, -0.0668, -0.0044],\n",
      "          [-0.1085, -0.0458,  0.0618, -0.0900,  0.0302],\n",
      "          [ 0.0656, -0.0159,  0.0961, -0.0391,  0.1091]],\n",
      "\n",
      "         [[-0.0855,  0.0566,  0.0784,  0.0431,  0.0622],\n",
      "          [-0.0634,  0.0776,  0.0915,  0.0016,  0.0485],\n",
      "          [ 0.0660, -0.0876,  0.0556, -0.0643, -0.0688],\n",
      "          [ 0.0721,  0.0825,  0.0123,  0.0413,  0.0423],\n",
      "          [ 0.0228, -0.0236, -0.0007, -0.1021,  0.0206]],\n",
      "\n",
      "         [[-0.0650, -0.0163, -0.0085,  0.0678,  0.0680],\n",
      "          [-0.1081, -0.0227, -0.0447,  0.0309,  0.0735],\n",
      "          [ 0.0886,  0.0277,  0.1030,  0.0124, -0.0774],\n",
      "          [-0.0229,  0.0570, -0.0419, -0.0002,  0.1131],\n",
      "          [ 0.0939, -0.0724, -0.0217,  0.0208,  0.1082]]],\n",
      "\n",
      "\n",
      "        [[[-0.0556, -0.0155,  0.0879,  0.0454,  0.1011],\n",
      "          [-0.0959,  0.0956,  0.0734, -0.1025,  0.0847],\n",
      "          [ 0.0572,  0.1096, -0.0528,  0.0339, -0.0893],\n",
      "          [ 0.0420, -0.0412,  0.0211,  0.0361, -0.0986],\n",
      "          [-0.0593, -0.0846,  0.0786,  0.0941,  0.0679]],\n",
      "\n",
      "         [[ 0.1006,  0.0426, -0.0070,  0.1063, -0.0021],\n",
      "          [ 0.0860,  0.0772, -0.1076, -0.0146,  0.1020],\n",
      "          [ 0.0897,  0.0799, -0.0876,  0.0618,  0.0360],\n",
      "          [ 0.0905,  0.0399, -0.0440,  0.1007,  0.0419],\n",
      "          [ 0.0776,  0.0037,  0.0205, -0.0406,  0.0515]],\n",
      "\n",
      "         [[-0.0144, -0.0229, -0.0174,  0.0135, -0.0678],\n",
      "          [ 0.0712, -0.0346,  0.0083, -0.1066, -0.0775],\n",
      "          [ 0.0824,  0.0926,  0.0008,  0.0948,  0.0213],\n",
      "          [ 0.0037, -0.0532, -0.0739, -0.0851,  0.0787],\n",
      "          [ 0.0242,  0.0670,  0.0391, -0.0244,  0.1108]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0291,  0.0363,  0.0379, -0.0578, -0.0688],\n",
      "          [-0.0626, -0.0554,  0.0552, -0.0375,  0.0398],\n",
      "          [ 0.0227, -0.0297,  0.0229,  0.0615, -0.0158],\n",
      "          [-0.0554,  0.0479,  0.0218, -0.0591,  0.0312],\n",
      "          [-0.0427, -0.0700,  0.0734, -0.0731,  0.0205]],\n",
      "\n",
      "         [[-0.0515,  0.0091,  0.0061, -0.0711,  0.0511],\n",
      "          [ 0.0987,  0.0794, -0.0799, -0.0842, -0.0196],\n",
      "          [ 0.0281, -0.0738, -0.0004,  0.0548, -0.0198],\n",
      "          [ 0.0728,  0.0296, -0.0449, -0.0425, -0.0414],\n",
      "          [-0.1004, -0.1001,  0.0183,  0.0115,  0.0902]],\n",
      "\n",
      "         [[-0.1038,  0.0801, -0.0071, -0.0801, -0.0147],\n",
      "          [ 0.0425,  0.0901,  0.0652,  0.0330, -0.0606],\n",
      "          [ 0.0303,  0.0772, -0.0024,  0.0781, -0.0642],\n",
      "          [-0.0519, -0.0019, -0.0435,  0.0471,  0.0083],\n",
      "          [ 0.0398, -0.0173,  0.0264, -0.0422, -0.0154]]]], requires_grad=True)\n",
      "------------------------------------\n",
      "tensor([[[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]],\n",
      "\n",
      "         [[True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True],\n",
      "          [True, True, True, True, True]]]])\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    " \n",
    " \n",
    " \n",
    "# define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    " \n",
    "# initial model\n",
    "model = TheModelClass()\n",
    " \n",
    "#initialize the optimizer\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    " \n",
    "# print the model's state_dict\n",
    "print(\"model's state_dict:\")\n",
    "print(model.state_dict().keys())\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor,'\\t',model.state_dict()[param_tensor].size())\n",
    " \n",
    "print(\"\\noptimizer's state_dict\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name,'\\t',optimizer.state_dict()[var_name])\n",
    " \n",
    "print(\"\\nprint particular param\")\n",
    "print('\\n',model.conv1.weight.size())\n",
    "print('\\n',model.conv1.weight)\n",
    " \n",
    "print(\"------------------------------------\")\n",
    "torch.save(model.state_dict(),'./model_state_dict.pt')\n",
    "# model_2 = TheModelClass()\n",
    "# model_2.load_state_dict(torch.load('./model_state_dict'))\n",
    "# model.eval()\n",
    "# print('\\n',model_2.conv1.weight)\n",
    "# print((model_2.conv1.weight == model.conv1.weight).size())\n",
    "## 仅仅加载某一层的参数\n",
    "conv1_weight_state = torch.load('./model_state_dict.pt')['conv1.weight']\n",
    "print(conv1_weight_state==model.conv1.weight)\n",
    " \n",
    "model_2 = TheModelClass()\n",
    "model_2.load_state_dict(torch.load('./model_state_dict.pt'))\n",
    "model_2.conv1.requires_grad=False\n",
    "print(model_2.conv1.requires_grad)\n",
    "print(model_2.conv1.bias.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def softmax(X):\n",
    "#     X_exp = X.exp()\n",
    "#     partition = X_exp.sum(dim=1, keepdim=True)\n",
    "#     # print(\"X size is \", X_exp.size())\n",
    "#     # print(\"partition size is \", partition, partition.size())\n",
    "#     return X_exp / partition  # 这里应用了广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-28307a1f5c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3c389ff4a2d9>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# print(\"X size is \", X_exp.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(\"partition size is \", partition, partition.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'exp'"
     ]
    }
   ],
   "source": [
    "# softmax([-2 -1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is true\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.sub('[^a-z]+', ' ','it is true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it is true\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('[^a-z]+', ' ','5it is true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  is true\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('[^a-z]+', ' ','it is true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
